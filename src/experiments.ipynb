{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from features import PreprocessData\n",
    "from linear_regression import linear_closed_form, linear_gradient_descent\n",
    "\n",
    "ppd = PreprocessData()\n",
    "\n",
    "# Split dataset\n",
    "train, validation, test = ppd.preprocess_data(ppd.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute most common words from \n",
    "ppd.compute_most_common_words(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features runtime: 54.67300200462341\n",
      "(10000, 169)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Compute features on training set\n",
    "start = time.time()\n",
    "X_train, y_train = ppd.compute_features(train)\n",
    "print(f'Training features runtime: {time.time() - start}')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation features runtime: 5.649372577667236\n",
      "(1000, 169)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# Compute features on validation set\n",
    "start = time.time()\n",
    "X_valid, y_valid = ppd.compute_features(validation)\n",
    "print(f'Validation features runtime: {time.time() - start}')\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed form runtime: 0.0246889591217041\n",
      "(169,)\n",
      "[ 3.72813474e-01 -1.07171749e+00 -2.39840127e-01 -5.70469727e-03\n",
      " -1.98003833e-02 -1.17976144e-02 -1.69695127e-02  1.48413874e-02\n",
      "  8.09634692e-04 -5.38523613e-02  5.68031632e-02  2.91587521e-02\n",
      "  2.25523375e-02  1.64385796e-02 -4.78980509e-02  5.03499956e-02\n",
      "  3.17068669e-02 -5.74007125e-02 -4.74424862e-02  5.08230645e-02\n",
      "  6.51800548e-02  3.96989382e-02 -4.61523244e-03  3.33011297e-02\n",
      " -3.18013480e-02 -2.81391696e-02 -2.32666644e-02  3.67059683e-02\n",
      "  7.28833031e-02  2.52553794e-02 -1.04995055e-02 -3.54680688e-03\n",
      "  2.02486171e-02  4.38487727e-02 -2.61883987e-02  3.79187237e-02\n",
      " -1.11101936e-02  5.46382715e-02 -8.56457285e-02  2.59442450e-03\n",
      "  2.78535429e-02  7.55701091e-03 -3.09200064e-02  1.74893596e-03\n",
      "  5.52236581e-02  5.03940857e-02 -2.94118240e-02 -5.84167548e-02\n",
      "  8.21143376e-02 -8.77610552e-03  2.90286854e-02  3.39495642e-02\n",
      "  1.73170477e-02 -8.35047328e-03  8.88709878e-03 -4.90170738e-02\n",
      " -3.26870339e-02  1.41099396e-03 -3.31504424e-01  3.17750121e-03\n",
      " -2.74193565e-02 -1.84594849e-02 -7.13397002e-02  1.42559050e-01\n",
      " -2.88177103e-02  2.78847074e-02 -6.46229231e-02  7.26767984e-02\n",
      " -1.37363281e-03 -6.88519662e-04  2.66864804e-02 -3.55696173e-02\n",
      " -3.92786403e-02 -9.07792403e-02  3.84025514e-03 -3.13325022e-02\n",
      "  2.16197790e-02  1.55968390e-02 -8.31220926e-02  9.29794031e-03\n",
      "  5.71591485e-03  4.08887912e-02 -5.30182107e-02 -3.97754069e-02\n",
      "  5.36822619e-02  4.59901254e-02  2.84142973e-02 -2.40795057e-02\n",
      "  8.31388903e-02 -3.43699436e-02  5.82317435e-02 -2.76494260e-02\n",
      "  4.87034532e-03 -9.26807710e-02 -5.06666944e-02  8.48507105e-03\n",
      " -3.36186826e-03 -1.77266535e-02 -1.45868723e-02  7.56062244e-02\n",
      " -7.94489430e-03 -1.84043513e-02  2.10733796e-02  1.51207485e-01\n",
      "  2.45363047e-02 -1.04057734e-01  4.48098876e-02  6.40644238e-02\n",
      "  7.78637509e-02  3.30776335e-02 -8.38632358e-03 -6.36337394e-02\n",
      "  7.49289450e-02  1.77730607e-02  3.24488071e-02  1.31261999e-01\n",
      "  5.43698660e-03 -8.12843562e-02 -8.19283512e-02 -1.15456425e-01\n",
      "  6.03376218e-02  6.99067137e-02  1.09159626e-01  2.24668128e-02\n",
      " -6.06084454e-02  1.30996244e-01  1.81350062e-02  1.50333466e-01\n",
      "  1.80208894e-02  4.72579971e-02 -1.32605332e-01 -2.70092066e-02\n",
      " -3.93656531e-02  9.49525105e-02 -1.43975462e-01 -3.79237402e-02\n",
      " -7.57631829e-02  6.24220990e-02 -2.19711267e-02  2.60363892e-02\n",
      " -6.09998892e-02  3.07226134e-03  1.41507611e-01 -4.55061791e-03\n",
      " -6.76451376e-03 -8.56199646e-02 -4.91089738e-03  5.72384606e-02\n",
      " -5.77014371e-02 -7.47168069e-02  6.49866174e-02  2.79692858e-01\n",
      " -2.69763142e-01 -1.46102543e-01 -8.68269117e-02 -8.45669198e-04\n",
      " -2.34051148e-02  5.47455590e-02 -2.36848058e-01  5.67003403e-02\n",
      "  4.54311489e-02 -3.95367740e-02  2.97655155e-02  7.56959276e-02\n",
      "  2.17983859e-03 -1.96320967e-03 -1.70047026e-02  3.61352397e-02\n",
      "  8.41011059e-01]\n"
     ]
    }
   ],
   "source": [
    "# Train using closed form method\n",
    "start = time.time()\n",
    "w_closed = linear_closed_form(X_train, y_train)\n",
    "print(f'Closed form runtime: {time.time() - start}')\n",
    "print(w_closed.shape)\n",
    "print(w_closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.7443156336966558e-05 | Learning rate: 3.9999996000000397e-08\n",
      "Error: 4.252082778944286e-06 | Learning rate: 3.9999992000001606e-08\n",
      "Error: 1.4317652289389837e-06 | Learning rate: 3.9999988000003604e-08\n",
      "Error: 6.318267645854112e-07 | Learning rate: 3.99999840000064e-08\n",
      "Error: 3.5092620684532515e-07 | Learning rate: 3.999998000001e-08\n",
      "Error: 2.2777086473070577e-07 | Learning rate: 3.9999976000014406e-08\n",
      "Error: 1.6050279296046633e-07 | Learning rate: 3.99999720000196e-08\n",
      "Error: 1.1759602040397989e-07 | Learning rate: 3.99999680000256e-08\n",
      "Finished after 855044 iterations\n",
      "(169,)\n",
      "[ 3.72809789e-01 -1.07102977e+00 -2.39924377e-01 -5.76377559e-03\n",
      " -1.98103660e-02 -1.18542503e-02 -1.70819038e-02  1.49976200e-02\n",
      "  6.69383237e-04 -5.40080692e-02  5.72548214e-02  2.92507071e-02\n",
      "  2.24754504e-02  1.60089718e-02 -4.82267272e-02  5.04044155e-02\n",
      "  3.20652671e-02 -5.73852376e-02 -4.75038709e-02  5.05689071e-02\n",
      "  6.52013150e-02  3.96392471e-02 -3.98711261e-03  3.37853261e-02\n",
      " -3.17506811e-02 -2.71905792e-02 -2.28725308e-02  3.65487614e-02\n",
      "  7.36948937e-02  2.50507819e-02 -1.10768374e-02 -3.05258964e-03\n",
      "  2.01616677e-02  4.36808589e-02 -2.62336412e-02  3.80654863e-02\n",
      " -1.10822743e-02  5.47462045e-02 -8.58703894e-02  3.15877433e-03\n",
      "  2.82253545e-02  7.51813668e-03 -3.07384259e-02  1.39628215e-03\n",
      "  5.56675976e-02  5.03622266e-02 -2.94393372e-02 -5.88397103e-02\n",
      "  8.23381108e-02 -8.61274936e-03  2.91440462e-02  3.42225653e-02\n",
      "  1.78010316e-02 -8.22612303e-03  8.72051795e-03 -5.00687351e-02\n",
      " -3.24148791e-02  1.19271479e-03 -3.31429863e-01  3.05206317e-03\n",
      " -2.73162494e-02 -1.86265076e-02 -7.13413474e-02  1.42621046e-01\n",
      " -2.91299534e-02  2.78455812e-02 -6.45729379e-02  7.25195181e-02\n",
      " -1.86110385e-03 -7.81850087e-04  2.66390340e-02 -3.55421426e-02\n",
      " -3.86229993e-02 -9.07713336e-02  3.95861310e-03 -3.16878879e-02\n",
      "  2.14169261e-02  1.60141868e-02 -8.34143006e-02  9.05402562e-03\n",
      "  5.60367053e-03  4.03996779e-02 -5.32290341e-02 -3.97403110e-02\n",
      "  5.37766210e-02  4.35290712e-02  2.85810550e-02 -2.53023936e-02\n",
      "  8.32292832e-02 -4.02218244e-02  5.85070726e-02 -2.74997039e-02\n",
      "  1.84153769e-03 -9.27152250e-02 -5.07240740e-02  8.49185613e-03\n",
      " -4.04487660e-03 -1.79544397e-02 -1.44498843e-02  7.59064899e-02\n",
      " -8.06012996e-03 -1.83789406e-02  1.95604102e-02  1.51346767e-01\n",
      "  2.41167620e-02 -1.05819246e-01  4.60518953e-02  6.40927719e-02\n",
      "  7.80479732e-02  3.27646438e-02 -8.25980827e-03 -6.35741483e-02\n",
      "  7.49151551e-02  1.75626677e-02  3.23223220e-02  1.31452486e-01\n",
      "  5.54079678e-03 -8.09565810e-02 -8.15287351e-02 -1.15446270e-01\n",
      "  6.06949864e-02  6.96525819e-02  1.08727143e-01  2.27110428e-02\n",
      " -6.09904943e-02  1.30580934e-01  1.80055188e-02  1.31384820e-01\n",
      "  1.83100506e-02  4.70434779e-02 -1.32337281e-01 -2.47281517e-02\n",
      " -3.92128220e-02  9.49494013e-02 -1.54912035e-01 -3.79835786e-02\n",
      " -7.58757479e-02  6.29236112e-02 -2.23476709e-02  2.57426284e-02\n",
      " -6.07122317e-02  3.09050735e-03  1.43940435e-01 -2.96788078e-03\n",
      " -7.27626699e-03 -8.64113604e-02 -4.73569843e-03  5.45277256e-02\n",
      " -5.81489977e-02 -7.38530074e-02  6.50127345e-02  3.09559081e-01\n",
      " -2.82121570e-01 -1.46553836e-01 -8.71872732e-02 -1.03141383e-03\n",
      " -2.34991286e-02  5.46950711e-02 -2.36789585e-01  5.72748102e-02\n",
      "  4.55893116e-02 -3.93290337e-03  2.95307059e-02  7.54306041e-02\n",
      "  2.25067284e-03 -1.97081658e-03 -1.69372568e-02  3.56003655e-02\n",
      "  8.40986881e-01]\n",
      "Gradient descent runtime: 15.63357663154602\n"
     ]
    }
   ],
   "source": [
    "# Train using gradient descent\n",
    "\n",
    "# Hyperparameters\n",
    "# w_init = np.zeros(X_train.shape[1])\n",
    "w_init = np.random.rand(X_train.shape[1])\n",
    "decay_speed = 10**(-12)\n",
    "learn_rate = 4*10**(-8)\n",
    "min_err = 10**(-7)\n",
    "max_iter = 10000000\n",
    "\n",
    "start = time.time()\n",
    "w_grad = linear_gradient_descent(X_train, y_train, w_init, decay_speed, learn_rate, min_err, max_iter)\n",
    "print(w_grad.shape)\n",
    "print(w_grad)\n",
    "print(f'Gradient descent runtime: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0463371860983777\n",
      "1.0463422161596414\n"
     ]
    }
   ],
   "source": [
    "# Compute MSE on training set\n",
    "y_closed_train = np.matmul(X_train, w_closed)\n",
    "mse_closed_train = np.sum((y_closed_train - y_train)**2)/len(y_train)\n",
    "print(mse_closed_train)\n",
    "\n",
    "y_grad_train = np.matmul(X_train, w_grad)\n",
    "mse_grad_train = np.sum((y_grad_train - y_train)**2)/len(y_train)\n",
    "print(mse_grad_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9942425147893313\n",
      "0.9942508493741995\n"
     ]
    }
   ],
   "source": [
    "# Compute MSE on validation set\n",
    "y_closed_valid = np.matmul(X_valid, w_closed)\n",
    "mse_closed_valid = np.sum((y_closed_valid - y_valid)**2)/len(y_valid)\n",
    "print(mse_closed_valid)\n",
    "\n",
    "y_grad_valid = np.matmul(X_valid, w_grad)\n",
    "mse_grad_valid = np.sum((y_grad_valid - y_valid)**2)/len(y_valid)\n",
    "print(mse_grad_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
