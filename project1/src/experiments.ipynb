{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "from tabulate import tabulate\n",
    "\n",
    "from features import PreprocessData\n",
    "from linear_regression import linear_closed_form, linear_gradient_descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize PPD\n",
    "ppd = PreprocessData()\n",
    "\n",
    "# Split dataset\n",
    "train, validation, test = ppd.preprocess_data(ppd.data)\n",
    "\n",
    "# Compute most common words from \n",
    "ppd.compute_most_common_words(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Experiments\n",
    "### 1 - Compare runtime, stability and performance of closed-form and gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n",
      "(1000, 4)\n",
      "Training features runtime: 0.014734745025634766\n",
      "Validation features runtime: 0.0016970634460449219\n"
     ]
    }
   ],
   "source": [
    "# Compute features on training set\n",
    "start = time.time()\n",
    "X_train, y_train = ppd.compute_features(train, simple=True)\n",
    "feat_train_runtime = time.time() - start\n",
    "print(X_train.shape)\n",
    "\n",
    "# Compute features on validation set\n",
    "start = time.time()\n",
    "X_valid, y_valid = ppd.compute_features(validation, simple=True)\n",
    "feat_valid_runtime = time.time() - start\n",
    "print(X_valid.shape)\n",
    "\n",
    "print(f'Training features runtime: {feat_train_runtime}')\n",
    "print(f'Validation features runtime: {feat_valid_runtime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_closed_vs_gradient(X_train, y_train, X_valid, y_valid, hyperparams, rand_init=False):\n",
    "    # Train using closed form method\n",
    "    start = time.time()\n",
    "    w_closed = linear_closed_form(X_train, y_train)\n",
    "    w_closed_runtime = time.time() - start\n",
    "    \n",
    "    # Train using gradient descent\n",
    "    # Hyperparameters\n",
    "    w_init = np.random.rand(X_train.shape[1]) if rand_init else np.zeros(X_train.shape[1])\n",
    "    decay_speed = hyperparams['decay_speed']\n",
    "    learn_rate = hyperparams['learn_rate']\n",
    "    min_err = hyperparams['min_err']\n",
    "    max_iter = hyperparams['max_iter']\n",
    "\n",
    "    start = time.time()\n",
    "    w_grad = linear_gradient_descent(X_train, y_train, w_init, decay_speed, learn_rate, min_err, max_iter, verbose=True)\n",
    "    w_grad_runtime = time.time() - start\n",
    "    \n",
    "    # Compute MSE on training set\n",
    "    y_closed_train = np.matmul(X_train, w_closed)\n",
    "    mse_closed_train = np.sum((y_closed_train - y_train)**2)/len(y_train)\n",
    "\n",
    "    y_grad_train = np.matmul(X_train, w_grad)\n",
    "    mse_grad_train = np.sum((y_grad_train - y_train)**2)/len(y_train)\n",
    "    \n",
    "    # Compute MSE on validation set\n",
    "    y_closed_valid = np.matmul(X_valid, w_closed)\n",
    "    mse_closed_valid = np.sum((y_closed_valid - y_valid)**2)/len(y_valid)\n",
    "\n",
    "    y_grad_valid = np.matmul(X_valid, w_grad)\n",
    "    mse_grad_valid = np.sum((y_grad_valid - y_valid)**2)/len(y_valid)\n",
    "    \n",
    "    return {'train': {'closed': mse_closed_train, 'grad': mse_grad_train}, 'validation': {'closed': mse_closed_valid, 'grad': mse_grad_valid}, 'runtime': {'closed': w_closed_runtime, 'grad': w_grad_runtime}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 - Testing random w0 vs. zero w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.008399417747629045 | Learning rate: 9.999999999989998e-07\n",
      "Error: 3.9112363860916306e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 3.891320541724275e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 3.8715061965104804e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 35866 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.012204837079564946 | Learning rate: 9.999999999989998e-07\n",
      "Error: 4.476479937860773e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 4.453685898173232e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 4.4310080275875416e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 36451 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.0045782447489308665 | Learning rate: 9.999999999989998e-07\n",
      "Error: 4.2678749152049e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 4.2461430831782526e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 4.2245220051247337e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 36244 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.019164174666932064 | Learning rate: 9.999999999989998e-07\n",
      "Error: 4.657797940621018e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 4.634080637570748e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 4.6104842076648784e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 36623 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.011023259487694101 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.6609178951994315e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.6473686179133707e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.633888393046265e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 34197 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.012247416077325017 | Learning rate: 9.999999999989998e-07\n",
      "Error: 3.838706870208881e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 3.8191603430850985e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 3.7997134344863596e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 35785 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.009279697812172815 | Learning rate: 9.999999999989998e-07\n",
      "Error: 3.815070104569466e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 3.7956439348157457e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 3.7763167686539023e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 35758 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.004688225641286051 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.552416919516705e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5394201243893352e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.5264895661210407e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 34017 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.019959643743336683 | Learning rate: 9.999999999989998e-07\n",
      "Error: 3.419991641897738e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 3.4025771941899818e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 3.3852514994581116e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 35285 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.009953321367718442 | Learning rate: 9.999999999989998e-07\n",
      "Error: 3.2304004383976324e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 3.2139513808880284e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 3.1975861559000414e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 35038 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.016307563815036244 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.597442003454916e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5842159425964156e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.571057287498957e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 34093 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.013388563390121403 | Learning rate: 9.999999999989998e-07\n",
      "Error: 3.6903993467450885e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 3.6716079949369554e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 3.6529124126009424e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 35614 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.011587666871659541 | Learning rate: 9.999999999989998e-07\n",
      "Error: 3.428980952559576e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 3.4115207318690674e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 3.3941494969681086e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 35296 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.01721450303828606 | Learning rate: 9.999999999989998e-07\n",
      "Error: 3.213737154908495e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 3.19737294608029e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 3.1810921364210565e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 35015 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.016622846689306785 | Learning rate: 9.999999999989998e-07\n",
      "Error: 4.0892193396326495e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 4.068397213866837e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 4.0476812058538865e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 36059 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.01275999819634257 | Learning rate: 9.999999999989998e-07\n",
      "Error: 3.498141992097964e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 3.4803296062895383e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 3.462607999640073e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 35383 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.024202623692722504 | Learning rate: 9.999999999989998e-07\n",
      "Error: 4.3892488102909015e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 4.366898947546856e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 4.3446629891983767e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 36366 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.002534795600313293 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.6780495671961112e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.664413056148817e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.650846042029726e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 34225 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.020149045262580493 | Learning rate: 9.999999999989998e-07\n",
      "Error: 4.467841552436782e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 4.445091498866764e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 4.422457389664594e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 36443 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n",
      "Error: 0.019546058500856254 | Learning rate: 9.999999999989998e-07\n",
      "Error: 3.510480050450736e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 3.4926048397432703e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 3.4748207297651203e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 35398 iterations\n",
      "Error: 0.02747409762411553 | Learning rate: 9.999999999989998e-07\n",
      "Error: 2.5240488827598966e-05 | Learning rate: 9.99999989999e-07\n",
      "Error: 2.5111965363145244e-06 | Learning rate: 9.999999799990004e-07\n",
      "Error: 2.4984096906422007e-07 | Learning rate: 9.99999969999001e-07\n",
      "Finished after 33968 iterations\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {'decay_speed': 10**(-12), 'learn_rate': 10**(-6), 'min_err': 10**(-7), 'max_iter': 1000000}\n",
    "rand_runtime = []\n",
    "zero_runtime = []\n",
    "closed_runtime = []\n",
    "for _ in range(20):\n",
    "    perf_rand = test_closed_vs_gradient(X_train, y_train, X_valid, y_valid, hyperparams, rand_init=True)\n",
    "    perf_zero = test_closed_vs_gradient(X_train, y_train, X_valid, y_valid, hyperparams, rand_init=False)\n",
    "    rand_runtime.append(perf_rand['runtime']['grad'])\n",
    "    zero_runtime.append(perf_zero['runtime']['grad'])\n",
    "    closed_runtime.append(perf_rand['runtime']['closed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime with random init: 0.4442092180252075\n",
      "Average runtime with zero init: 0.4232942581176758\n",
      "Average runtime with closed form: 0.0019019603729248046\n",
      "Closed-form Training MSE: 1.0846830709157251\n",
      "Gradient descent Training MSE: 1.0846830730810026\n",
      "Closed-form Validation MSE: 1.0203266848431447\n",
      "Gradient descent Validation MSE: 1.0203284850569836\n"
     ]
    }
   ],
   "source": [
    "print(f'Average runtime with random init: {sum(rand_runtime)/len(rand_runtime)}')\n",
    "print(f'Average runtime with zero init: {sum(zero_runtime)/len(zero_runtime)}')\n",
    "print(f'Average runtime with closed form: {sum(closed_runtime)/len(closed_runtime)}')\n",
    "\n",
    "print('Closed-form Training MSE: ' + str(perf_rand['train']['closed']))\n",
    "print(f'Gradient descent Training MSE: ' + str(perf_rand['train']['grad']))\n",
    "\n",
    "print(f'Closed-form Validation MSE: ' + str(perf_rand['validation']['closed']))\n",
    "print(f'Gradient descent Validation MSE: ' + str(perf_rand['validation']['grad']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 - Testing different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with learn_rate: 1e-05 and decay_speed: 1e-05\n",
      "Error: 0.2747382288591415 | Learning rate: 9.99990000099999e-06\n",
      "Finished after 4469 iterations\n",
      "Testing with learn_rate: 1e-05 and decay_speed: 1e-06\n",
      "Error: 0.27474070150072866 | Learning rate: 9.999990000010002e-06\n",
      "Finished after 4398 iterations\n",
      "Testing with learn_rate: 1e-05 and decay_speed: 1e-07\n",
      "Error: 0.27474094876733524 | Learning rate: 9.9999990000001e-06\n",
      "Finished after 4391 iterations\n",
      "Testing with learn_rate: 1e-05 and decay_speed: 1e-08\n",
      "Error: 0.2747409734940204 | Learning rate: 9.999999900000003e-06\n",
      "Finished after 4391 iterations\n",
      "Testing with learn_rate: 1e-05 and decay_speed: 1e-09\n",
      "Error: 0.2747409759666891 | Learning rate: 9.99999999e-06\n",
      "Finished after 4391 iterations\n",
      "Testing with learn_rate: 1e-05 and decay_speed: 1e-10\n",
      "Error: 0.274740976213956 | Learning rate: 9.999999999e-06\n",
      "Finished after 4391 iterations\n",
      "Testing with learn_rate: 1e-06 and decay_speed: 1e-05\n",
      "Error: 0.02747382288591415 | Learning rate: 9.99990000099999e-07\n",
      "Finished after 38483 iterations\n",
      "Testing with learn_rate: 1e-06 and decay_speed: 1e-06\n",
      "Error: 0.02747407015007286 | Learning rate: 9.99999000001e-07\n",
      "Finished after 34400 iterations\n",
      "Testing with learn_rate: 1e-06 and decay_speed: 1e-07\n",
      "Error: 0.027474094876733524 | Learning rate: 9.9999990000001e-07\n",
      "Finished after 34011 iterations\n",
      "Testing with learn_rate: 1e-06 and decay_speed: 1e-08\n",
      "Error: 0.02747409734940204 | Learning rate: 9.999999900000001e-07\n",
      "Finished after 33973 iterations\n",
      "Testing with learn_rate: 1e-06 and decay_speed: 1e-09\n",
      "Error: 0.027474097596668908 | Learning rate: 9.999999989999998e-07\n",
      "Finished after 33969 iterations\n",
      "Testing with learn_rate: 1e-06 and decay_speed: 1e-10\n",
      "Error: 0.027474097621395594 | Learning rate: 9.999999998999999e-07\n",
      "Finished after 33968 iterations\n",
      "Testing with learn_rate: 1e-07 and decay_speed: 1e-05\n",
      "Error: 0.002747382288591415 | Learning rate: 9.999900000999989e-08\n",
      "Error: 2.5625691946496684e-06 | Learning rate: 4.999975000124999e-08\n",
      "Error: 6.702962758012263e-07 | Learning rate: 3.333322222259259e-08\n",
      "Error: 2.588458863792457e-07 | Learning rate: 2.499993750015625e-08\n",
      "Error: 1.2374243859709912e-07 | Learning rate: 1.9999960000079996e-08\n",
      "Finished after 433265 iterations\n",
      "Testing with learn_rate: 1e-07 and decay_speed: 1e-06\n",
      "Error: 0.002747407015007286 | Learning rate: 9.99999000001e-08\n",
      "Error: 2.5574491828482046e-06 | Learning rate: 9.090900826453793e-08\n",
      "Error: 3.148240100617015e-07 | Learning rate: 8.333326388894677e-08\n",
      "Finished after 258549 iterations\n",
      "Testing with learn_rate: 1e-07 and decay_speed: 1e-07\n",
      "Error: 0.002747409487673352 | Learning rate: 9.999999000000099e-08\n",
      "Error: 2.5284707292476098e-06 | Learning rate: 9.900989118713948e-08\n",
      "Error: 2.5779109804470163e-07 | Learning rate: 9.803920607458763e-08\n",
      "Finished after 241766 iterations\n",
      "Testing with learn_rate: 1e-07 and decay_speed: 1e-08\n",
      "Error: 0.0027474097349402034 | Learning rate: 9.9999999e-08\n",
      "Error: 2.5250412798798626e-06 | Learning rate: 9.99000989020969e-08\n",
      "Error: 2.5189682711475206e-07 | Learning rate: 9.980039820558484e-08\n",
      "Finished after 240109 iterations\n",
      "Testing with learn_rate: 1e-07 and decay_speed: 1e-09\n",
      "Error: 0.002747409759666891 | Learning rate: 9.999999989999999e-08\n",
      "Error: 2.5246925960855296e-06 | Learning rate: 9.999000089992e-08\n",
      "Error: 2.513057240057368e-07 | Learning rate: 9.998000389924014e-08\n",
      "Finished after 239943 iterations\n",
      "Testing with learn_rate: 1e-07 and decay_speed: 1e-10\n",
      "Error: 0.00274740976213956 | Learning rate: 9.999999998999999e-08\n",
      "Error: 2.5246576699235452e-06 | Learning rate: 9.999900000000009e-08\n",
      "Error: 2.512465972827634e-07 | Learning rate: 9.99980000299996e-08\n",
      "Finished after 239927 iterations\n",
      "Testing with learn_rate: 1e-08 and decay_speed: 1e-05\n",
      "Error: 0.0002747382288591415 | Learning rate: 9.99990000099999e-09\n",
      "Error: 1.3018322268924004e-06 | Learning rate: 4.999975000124999e-09\n",
      "Error: 6.636203591329265e-07 | Learning rate: 3.333322222259259e-09\n",
      "Error: 4.612250589151681e-07 | Learning rate: 2.499993750015625e-09\n",
      "Error: 3.500851118550383e-07 | Learning rate: 1.9999960000079998e-09\n",
      "Error: 2.796659704234259e-07 | Learning rate: 1.6666638888935184e-09\n",
      "Error: 2.3132672666787164e-07 | Learning rate: 1.4285693877580175e-09\n",
      "Error: 1.9626684707649927e-07 | Learning rate: 1.2499984375019531e-09\n",
      "Error: 1.6978113437009354e-07 | Learning rate: 1.1111098765445814e-09\n",
      "Error: 1.491327479023552e-07 | Learning rate: 9.999990000009998e-10\n",
      "Error: 1.3262609928709303e-07 | Learning rate: 9.090900826453793e-10\n",
      "Error: 1.1915736584462486e-07 | Learning rate: 8.333326388894676e-10\n",
      "Error: 1.0797858949160311e-07 | Learning rate: 7.69230177515248e-10\n",
      "Finished after 1283665 iterations\n",
      "Testing with learn_rate: 1e-08 and decay_speed: 1e-06\n",
      "Error: 0.00027474070150072864 | Learning rate: 9.999990000010001e-09\n",
      "Error: 1.9109802384167213e-06 | Learning rate: 9.090900826453793e-09\n",
      "Error: 1.388197742222252e-06 | Learning rate: 8.333326388894677e-09\n",
      "Error: 1.0652595759812004e-06 | Learning rate: 7.692301775152481e-09\n",
      "Error: 8.336945928693934e-07 | Learning rate: 7.142852040819971e-09\n",
      "Error: 6.63599262909126e-07 | Learning rate: 6.666662222225185e-09\n",
      "Error: 5.360471821609432e-07 | Learning rate: 6.2499960937524414e-09\n",
      "Error: 4.3865395546603485e-07 | Learning rate: 5.882349480970894e-09\n",
      "Error: 3.630947172264289e-07 | Learning rate: 5.555552469137517e-09\n",
      "Error: 3.0363930444127113e-07 | Learning rate: 5.263155124655197e-09\n",
      "Error: 2.5625981207769267e-07 | Learning rate: 4.99999750000125e-09\n",
      "Error: 2.180712964115338e-07 | Learning rate: 4.761902494332146e-09\n",
      "Error: 1.869723299030524e-07 | Learning rate: 4.545452479339783e-09\n",
      "Error: 1.6140872436520531e-07 | Learning rate: 4.3478241965981756e-09\n",
      "Error: 1.4021502209097453e-07 | Learning rate: 4.166664930556279e-09\n",
      "Error: 1.225061790978986e-07 | Learning rate: 3.99999840000064e-09\n",
      "Error: 1.0760229126800695e-07 | Learning rate: 3.846152366864475e-09\n",
      "Finished after 1658243 iterations\n",
      "Testing with learn_rate: 1e-08 and decay_speed: 1e-07\n",
      "Error: 0.00027474094876733525 | Learning rate: 9.999999000000099e-09\n",
      "Error: 2.0441807691924974e-06 | Learning rate: 9.900989118713948e-09\n",
      "Error: 1.5749949211849783e-06 | Learning rate: 9.803920607458763e-09\n",
      "Error: 1.2452830122309774e-06 | Learning rate: 9.708736921481852e-09\n",
      "Error: 9.86846699171809e-07 | Learning rate: 9.615383690828491e-09\n",
      "Error: 7.837869460193227e-07 | Learning rate: 9.523808616780131e-09\n",
      "Error: 6.238709038573358e-07 | Learning rate: 9.433961374154589e-09\n",
      "Error: 4.976476973917158e-07 | Learning rate: 9.34579351908472e-09\n",
      "Error: 3.977979266783726e-07 | Learning rate: 9.25925840192052e-09\n",
      "Error: 3.1863937814961706e-07 | Learning rate: 9.17431108492559e-09\n",
      "Error: 2.557504566558602e-07 | Learning rate: 9.090908264462886e-09\n",
      "Error: 2.056825756079319e-07 | Learning rate: 9.00900819738665e-09\n",
      "Error: 1.6573994823793195e-07 | Learning rate: 8.928570631377623e-09\n",
      "Error: 1.338105700791439e-07 | Learning rate: 8.84955673897728e-09\n",
      "Error: 1.0823618630730152e-07 | Learning rate: 8.771929055093942e-09\n",
      "Finished after 1437540 iterations\n",
      "Testing with learn_rate: 1e-08 and decay_speed: 1e-08\n",
      "Error: 0.0002747409734940204 | Learning rate: 9.999999900000002e-09\n",
      "Error: 2.058892447645946e-06 | Learning rate: 9.99000989020969e-09\n",
      "Error: 1.5967356802863034e-06 | Learning rate: 9.980039820558486e-09\n",
      "Error: 1.267164992555123e-06 | Learning rate: 9.97008963140489e-09\n",
      "Error: 1.0058648421392189e-06 | Learning rate: 9.960159263345029e-09\n",
      "Error: 7.986305864944009e-07 | Learning rate: 9.950248657211455e-09\n",
      "Error: 6.342374689234609e-07 | Learning rate: 9.940357754071991e-09\n",
      "Error: 5.037989979332597e-07 | Learning rate: 9.930486495228534e-09\n",
      "Error: 4.002782143999409e-07 | Learning rate: 9.920634822215925e-09\n",
      "Error: 3.1810145946490634e-07 | Learning rate: 9.910802676800765e-09\n",
      "Error: 2.528530676193698e-07 | Learning rate: 9.900990000980297e-09\n",
      "Error: 2.0103397212142387e-07 | Learning rate: 9.891196736981239e-09\n",
      "Error: 1.59870799575258e-07 | Learning rate: 9.881422827258668e-09\n",
      "Error: 1.2716485851725523e-07 | Learning rate: 9.871668214494884e-09\n",
      "Error: 1.0117265703016054e-07 | Learning rate: 9.861932841598297e-09\n",
      "Finished after 1405102 iterations\n",
      "Testing with learn_rate: 1e-08 and decay_speed: 1e-09\n",
      "Error: 0.00027474097596668907 | Learning rate: 9.999999989999999e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 2.0603788007121167e-06 | Learning rate: 9.999000089992e-09\n",
      "Error: 1.5989456681876927e-06 | Learning rate: 9.998000389924015e-09\n",
      "Error: 1.2694011044495228e-06 | Learning rate: 9.997000889736079e-09\n",
      "Error: 1.00781369540853e-06 | Learning rate: 9.99600158936825e-09\n",
      "Error: 8.001504629570275e-07 | Learning rate: 9.995002488760618e-09\n",
      "Error: 6.352915537350452e-07 | Learning rate: 9.994003587853284e-09\n",
      "Error: 5.044109607614196e-07 | Learning rate: 9.993004886586385e-09\n",
      "Error: 4.0050317224566204e-07 | Learning rate: 9.992006384900074e-09\n",
      "Error: 3.180075382693134e-07 | Learning rate: 9.991008082734531e-09\n",
      "Error: 2.5251017144842116e-07 | Learning rate: 9.990009980029961e-09\n",
      "Error: 2.0050737163661978e-07 | Learning rate: 9.98901207672659e-09\n",
      "Error: 1.5921787179769127e-07 | Learning rate: 9.988014372764669e-09\n",
      "Error: 1.2643382779808523e-07 | Learning rate: 9.987016868084474e-09\n",
      "Error: 1.0040255352013498e-07 | Learning rate: 9.986019562626305e-09\n",
      "Finished after 1401743 iterations\n",
      "Testing with learn_rate: 1e-08 and decay_speed: 1e-10\n",
      "Error: 0.000274740976213956 | Learning rate: 9.999999999e-09\n",
      "Error: 2.0605275892567976e-06 | Learning rate: 9.99990000000001e-09\n",
      "Error: 1.599167032325702e-06 | Learning rate: 9.999800002999962e-09\n",
      "Error: 1.2696252060751359e-06 | Learning rate: 9.99970000799979e-09\n",
      "Error: 1.008009064030572e-06 | Learning rate: 9.99960001499944e-09\n",
      "Error: 8.003028150104507e-07 | Learning rate: 9.999500023998852e-09\n",
      "Error: 6.353971371200977e-07 | Learning rate: 9.999400034997961e-09\n",
      "Error: 5.044721145505733e-07 | Learning rate: 9.99930004799671e-09\n",
      "Error: 4.005254142474234e-07 | Learning rate: 9.99920006299504e-09\n",
      "Error: 3.1799771072238635e-07 | Learning rate: 9.999100079992891e-09\n",
      "Error: 2.5247530802196475e-07 | Learning rate: 9.999000098990202e-09\n",
      "Error: 2.0045404752821876e-07 | Learning rate: 9.99890011998691e-09\n",
      "Error: 1.591518719678352e-07 | Learning rate: 9.998800142982963e-09\n",
      "Error: 1.2636001660784782e-07 | Learning rate: 9.998700167978293e-09\n",
      "Error: 1.0032486851641871e-07 | Learning rate: 9.998600194972844e-09\n",
      "Finished after 1401406 iterations\n",
      "Testing with learn_rate: 1e-09 and decay_speed: 1e-05\n",
      "Error: 2.7473822885914153e-05 | Learning rate: 9.99990000099999e-10\n",
      "Error: 1.4391230275045419e-06 | Learning rate: 4.999975000125e-10\n",
      "Error: 5.629318494859303e-07 | Learning rate: 3.333322222259259e-10\n",
      "Error: 3.4585540593331104e-07 | Learning rate: 2.499993750015625e-10\n",
      "Error: 2.4665548625740987e-07 | Learning rate: 1.999996000008e-10\n",
      "Error: 1.8948632369226043e-07 | Learning rate: 1.6666638888935186e-10\n",
      "Error: 1.5237061930159347e-07 | Learning rate: 1.4285693877580175e-10\n",
      "Error: 1.2644025810652302e-07 | Learning rate: 1.2499984375019533e-10\n",
      "Error: 1.0738736219702865e-07 | Learning rate: 1.1111098765445815e-10\n",
      "Finished after 847658 iterations\n",
      "Testing with learn_rate: 1e-09 and decay_speed: 1e-06\n",
      "Error: 2.7474070150072866e-05 | Learning rate: 9.999990000010002e-10\n",
      "Error: 1.7711687049777111e-06 | Learning rate: 9.090900826453795e-10\n",
      "Error: 9.348927191130001e-07 | Learning rate: 8.333326388894678e-10\n",
      "Error: 6.341619829260678e-07 | Learning rate: 7.692301775152481e-10\n",
      "Error: 4.530348050481812e-07 | Learning rate: 7.142852040819971e-10\n",
      "Error: 3.3679937543732407e-07 | Learning rate: 6.666662222225184e-10\n",
      "Error: 2.602329002787046e-07 | Learning rate: 6.249996093752442e-10\n",
      "Error: 2.0869556675609059e-07 | Learning rate: 5.882349480970895e-10\n",
      "Error: 1.7324547085271426e-07 | Learning rate: 5.555552469137517e-10\n",
      "Error: 1.482690654006719e-07 | Learning rate: 5.263155124655198e-10\n",
      "Error: 1.3018481933707936e-07 | Learning rate: 4.99999750000125e-10\n",
      "Error: 1.1668918028237524e-07 | Learning rate: 4.761902494332147e-10\n",
      "Error: 1.0629439760350934e-07 | Learning rate: 4.5454524793397826e-10\n",
      "Finished after 1274218 iterations\n",
      "Testing with learn_rate: 1e-09 and decay_speed: 1e-07\n",
      "Error: 2.747409487673352e-05 | Learning rate: 9.9999990000001e-10\n",
      "Error: 1.8435040091168404e-06 | Learning rate: 9.900989118713948e-10\n",
      "Error: 1.0313403059168574e-06 | Learning rate: 9.803920607458764e-10\n",
      "Error: 7.101891198188101e-07 | Learning rate: 9.708736921481852e-10\n",
      "Error: 5.06721253801101e-07 | Learning rate: 9.615383690828492e-10\n",
      "Error: 3.773544058836956e-07 | Learning rate: 9.52380861678013e-10\n",
      "Error: 2.973265385144961e-07 | Learning rate: 9.43396137415459e-10\n",
      "Error: 2.4916043642029646e-07 | Learning rate: 9.34579351908472e-10\n",
      "Error: 2.204100019442207e-07 | Learning rate: 9.25925840192052e-10\n",
      "Error: 2.0274470913962063e-07 | Learning rate: 9.17431108492559e-10\n",
      "Error: 1.9109892883240152e-07 | Learning rate: 9.090908264462887e-10\n",
      "Error: 1.8264703834157997e-07 | Learning rate: 9.00900819738665e-10\n",
      "Error: 1.7590113339767735e-07 | Learning rate: 8.928570631377623e-10\n",
      "Error: 1.701011185303568e-07 | Learning rate: 8.84955673897728e-10\n",
      "Error: 1.6486267040025216e-07 | Learning rate: 8.771929055093943e-10\n",
      "Error: 1.5999058641311528e-07 | Learning rate: 8.695651417769443e-10\n",
      "Error: 1.553839160986342e-07 | Learning rate: 8.620688912009577e-10\n",
      "Error: 1.5098864984711402e-07 | Learning rate: 8.547007816495059e-10\n",
      "Error: 1.4677428105979023e-07 | Learning rate: 8.474575553002073e-10\n",
      "Error: 1.4272219734657642e-07 | Learning rate: 8.403360638373056e-10\n",
      "Error: 1.388199113726471e-07 | Learning rate: 8.333332638888947e-10\n",
      "Error: 1.350581766647318e-07 | Learning rate: 8.264462126903957e-10\n",
      "Error: 1.3142953449729364e-07 | Learning rate: 8.196720639613062e-10\n",
      "Error: 1.2792757398474483e-07 | Learning rate: 8.130080639830842e-10\n",
      "Error: 1.245465498732171e-07 | Learning rate: 8.064515478668107e-10\n",
      "Error: 1.2128118020418227e-07 | Learning rate: 7.999999360000052e-10\n",
      "Error: 1.1812653622452312e-07 | Learning rate: 7.936507306626404e-10\n",
      "Error: 1.1507797917133957e-07 | Learning rate: 7.874015128030306e-10\n",
      "Error: 1.121311216269839e-07 | Learning rate: 7.812499389648485e-10\n",
      "Error: 1.0928180175969774e-07 | Learning rate: 7.751937383570747e-10\n",
      "Error: 1.0652606473596185e-07 | Learning rate: 7.692307100591761e-10\n",
      "Error: 1.0386014815108717e-07 | Learning rate: 7.633587203542963e-10\n",
      "Error: 1.0128046979277662e-07 | Learning rate: 7.575757001836591e-10\n",
      "Finished after 3250878 iterations\n",
      "Testing with learn_rate: 1e-09 and decay_speed: 1e-08\n",
      "Error: 2.7474097349402043e-05 | Learning rate: 9.999999900000002e-10\n",
      "Error: 1.8515188548781195e-06 | Learning rate: 9.990009890209691e-10\n",
      "Error: 1.042459511734069e-06 | Learning rate: 9.980039820558487e-10\n",
      "Error: 7.19133408037977e-07 | Learning rate: 9.97008963140489e-10\n",
      "Error: 5.132754359748419e-07 | Learning rate: 9.960159263345029e-10\n",
      "Error: 3.8292641187746293e-07 | Learning rate: 9.950248657211456e-10\n",
      "Error: 3.035023212542596e-07 | Learning rate: 9.940357754071992e-10\n",
      "Error: 2.570050393200489e-07 | Learning rate: 9.930486495228535e-10\n",
      "Error: 2.302776539210859e-07 | Learning rate: 9.920634822215927e-10\n",
      "Error: 2.1449944593221783e-07 | Learning rate: 9.910802676800767e-10\n",
      "Error: 2.0441878531182204e-07 | Learning rate: 9.900990000980298e-10\n",
      "Error: 1.972057788464257e-07 | Learning rate: 9.89119673698124e-10\n",
      "Error: 1.914307453419132e-07 | Learning rate: 9.881422827258669e-10\n",
      "Error: 1.8639645829770465e-07 | Learning rate: 9.871668214494884e-10\n",
      "Error: 1.8176841963690324e-07 | Learning rate: 9.861932841598297e-10\n",
      "Error: 1.7738684650567695e-07 | Learning rate: 9.8522166517023e-10\n",
      "Error: 1.7317500403266077e-07 | Learning rate: 9.84251958816418e-10\n",
      "Error: 1.6909540687774063e-07 | Learning rate: 9.832841594563995e-10\n",
      "Error: 1.651290895470882e-07 | Learning rate: 9.823182614703513e-10\n",
      "Error: 1.6126583538225612e-07 | Learning rate: 9.813542592605079e-10\n",
      "Error: 1.574995775236912e-07 | Learning rate: 9.803921472510576e-10\n",
      "Error: 1.538262354949028e-07 | Learning rate: 9.79431919888032e-10\n",
      "Error: 1.502426961157961e-07 | Learning rate: 9.78473571639202e-10\n",
      "Error: 1.467463332200341e-07 | Learning rate: 9.775170969939678e-10\n",
      "Error: 1.4333478037979785e-07 | Learning rate: 9.76562490463257e-10\n",
      "Error: 1.4000582335419036e-07 | Learning rate: 9.756097465794171e-10\n",
      "Error: 1.3675734820354914e-07 | Learning rate: 9.746588598961126e-10\n",
      "Error: 1.3358731631168425e-07 | Learning rate: 9.737098249882198e-10\n",
      "Error: 1.3049375160040538e-07 | Learning rate: 9.727626364517255e-10\n",
      "Error: 1.2747473388802043e-07 | Learning rate: 9.718172889036221e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.2452839526340522e-07 | Learning rate: 9.70873776981808e-10\n",
      "Error: 1.2165291694273957e-07 | Learning rate: 9.699320953449845e-10\n",
      "Error: 1.1884652821552367e-07 | Learning rate: 9.689922386725559e-10\n",
      "Error: 1.161075042443898e-07 | Learning rate: 9.680542016645286e-10\n",
      "Error: 1.1343416509604045e-07 | Learning rate: 9.671179790414122e-10\n",
      "Error: 1.1082487410964419e-07 | Learning rate: 9.661835655441202e-10\n",
      "Error: 1.0827803721719754e-07 | Learning rate: 9.652509559338712e-10\n",
      "Error: 1.0579210156296934e-07 | Learning rate: 9.64320144992091e-10\n",
      "Error: 1.0336555391600787e-07 | Learning rate: 9.633911275203168e-10\n",
      "Error: 1.0099692060662744e-07 | Learning rate: 9.624638983400973e-10\n",
      "Finished after 3942822 iterations\n",
      "Testing with learn_rate: 1e-09 and decay_speed: 1e-09\n",
      "Error: 2.747409759666891e-05 | Learning rate: 9.99999999e-10\n",
      "Error: 1.8523289060166724e-06 | Learning rate: 9.999000089992e-10\n",
      "Error: 1.0435884487079811e-06 | Learning rate: 9.998000389924015e-10\n",
      "Error: 7.200441406639282e-07 | Learning rate: 9.997000889736078e-10\n",
      "Error: 5.139470583925722e-07 | Learning rate: 9.996001589368252e-10\n",
      "Error: 3.8350839433408263e-07 | Learning rate: 9.995002488760617e-10\n",
      "Error: 3.041643269656955e-07 | Learning rate: 9.994003587853285e-10\n",
      "Error: 2.578599110067119e-07 | Learning rate: 9.993004886586385e-10\n",
      "Error: 2.3136064599564695e-07 | Learning rate: 9.992006384900074e-10\n",
      "Error: 2.1579393703457362e-07 | Learning rate: 9.99100808273453e-10\n",
      "Error: 2.0588993098729926e-07 | Learning rate: 9.99000998002996e-10\n",
      "Error: 1.988194875738296e-07 | Learning rate: 9.98901207672659e-10\n",
      "Error: 1.931595826559704e-07 | Learning rate: 9.98801437276467e-10\n",
      "Error: 1.8821964719966752e-07 | Learning rate: 9.987016868084474e-10\n",
      "Error: 1.8367023324926944e-07 | Learning rate: 9.986019562626306e-10\n",
      "Error: 1.7935501681385738e-07 | Learning rate: 9.985022456330483e-10\n",
      "Error: 1.7519954431370757e-07 | Learning rate: 9.984025549137357e-10\n",
      "Error: 1.7116783522026022e-07 | Learning rate: 9.983028840987295e-10\n",
      "Error: 1.6724194513454387e-07 | Learning rate: 9.98203233182069e-10\n",
      "Error: 1.63412386157287e-07 | Learning rate: 9.981036021577966e-10\n",
      "Error: 1.5967364613511667e-07 | Learning rate: 9.980039910199561e-10\n",
      "Error: 1.560220942508931e-07 | Learning rate: 9.979043997625942e-10\n",
      "Error: 1.5245500280962133e-07 | Learning rate: 9.978048283797598e-10\n",
      "Error: 1.4897008965763301e-07 | Learning rate: 9.97705276865504e-10\n",
      "Error: 1.4556530391427715e-07 | Learning rate: 9.97605745213881e-10\n",
      "Error: 1.4223872562871236e-07 | Learning rate: 9.975062334189465e-10\n",
      "Error: 1.3898851816487954e-07 | Learning rate: 9.97406741474759e-10\n",
      "Error: 1.3581290564083098e-07 | Learning rate: 9.973072693753794e-10\n",
      "Error: 1.3271016174457074e-07 | Learning rate: 9.972078171148707e-10\n",
      "Error: 1.296786039351435e-07 | Learning rate: 9.971083846872985e-10\n",
      "Error: 1.267165908594895e-07 | Learning rate: 9.970089720867308e-10\n",
      "Error: 1.2382251938712573e-07 | Learning rate: 9.969095793072381e-10\n",
      "Error: 1.2099482448820745e-07 | Learning rate: 9.968102063428925e-10\n",
      "Error: 1.18231977007452e-07 | Learning rate: 9.967108531877696e-10\n",
      "Error: 1.1553248375774796e-07 | Learning rate: 9.966115198359464e-10\n",
      "Error: 1.12894885610863e-07 | Learning rate: 9.965122062815026e-10\n",
      "Error: 1.1031775750407869e-07 | Learning rate: 9.964129125185205e-10\n",
      "Error: 1.077997073071715e-07 | Learning rate: 9.963136385410845e-10\n",
      "Error: 1.0533937503117743e-07 | Learning rate: 9.96214384343281e-10\n",
      "Error: 1.0293543211131553e-07 | Learning rate: 9.961151499192e-10\n",
      "Error: 1.0058658073789172e-07 | Learning rate: 9.960159352629324e-10\n",
      "Finished after 4025340 iterations\n",
      "Testing with learn_rate: 1e-09 and decay_speed: 1e-10\n",
      "Error: 2.7474097621395605e-05 | Learning rate: 9.999999999000001e-10\n",
      "Error: 1.852409997605766e-06 | Learning rate: 9.99990000000001e-10\n",
      "Error: 1.0437015152220016e-06 | Learning rate: 9.999800002999962e-10\n",
      "Error: 7.20135380604141e-07 | Learning rate: 9.99970000799979e-10\n",
      "Error: 5.140143890074036e-07 | Learning rate: 9.999600014999441e-10\n",
      "Error: 3.835668559997372e-07 | Learning rate: 9.99950002399885e-10\n",
      "Error: 3.0423100516118763e-07 | Learning rate: 9.999400034997962e-10\n",
      "Error: 2.5794615769474e-07 | Learning rate: 9.999300047996711e-10\n",
      "Error: 2.3146998540603625e-07 | Learning rate: 9.99920006299504e-10\n",
      "Error: 2.1592467748164166e-07 | Learning rate: 9.999100079992891e-10\n",
      "Error: 2.060385640485373e-07 | Learning rate: 9.999000098990201e-10\n",
      "Error: 1.9898259300704838e-07 | Learning rate: 9.99890011998691e-10\n",
      "Error: 1.9333441437441453e-07 | Learning rate: 9.998800142982963e-10\n",
      "Error: 1.8840412814567194e-07 | Learning rate: 9.998700167978294e-10\n",
      "Error: 1.8386279167733153e-07 | Learning rate: 9.998600194972845e-10\n",
      "Error: 1.7955442536158418e-07 | Learning rate: 9.998500223966554e-10\n",
      "Error: 1.7540480194005301e-07 | Learning rate: 9.998400254959367e-10\n",
      "Error: 1.713780892544902e-07 | Learning rate: 9.998300287951219e-10\n",
      "Error: 1.6745644335695878e-07 | Learning rate: 9.99820032294205e-10\n",
      "Error: 1.6363044766971136e-07 | Learning rate: 9.998100359931804e-10\n",
      "Error: 1.598946441760171e-07 | Learning rate: 9.998000398920417e-10\n",
      "Error: 1.5624544603011672e-07 | Learning rate: 9.99790043990783e-10\n",
      "Error: 1.526801632430811e-07 | Learning rate: 9.997800482893984e-10\n",
      "Error: 1.4919654734820488e-07 | Learning rate: 9.99770052787882e-10\n",
      "Error: 1.4579257845721456e-07 | Learning rate: 9.997600574862274e-10\n",
      "Error: 1.4246636565155302e-07 | Learning rate: 9.997500623844288e-10\n",
      "Error: 1.3921609972465136e-07 | Learning rate: 9.997400674824808e-10\n",
      "Error: 1.360400307773701e-07 | Learning rate: 9.997300727803763e-10\n",
      "Error: 1.329364573172748e-07 | Learning rate: 9.997200782781101e-10\n",
      "Error: 1.2990372067477973e-07 | Learning rate: 9.997100839756761e-10\n",
      "Error: 1.2694020169306077e-07 | Learning rate: 9.99700089873068e-10\n",
      "Error: 1.2404431934129294e-07 | Learning rate: 9.996900959702802e-10\n",
      "Error: 1.2121452898655984e-07 | Learning rate: 9.996801022673064e-10\n",
      "Error: 1.184493211857943e-07 | Learning rate: 9.996701087641409e-10\n",
      "Error: 1.1574722155911294e-07 | Learning rate: 9.996601154607773e-10\n",
      "Error: 1.1310678921907083e-07 | Learning rate: 9.996501223572098e-10\n",
      "Error: 1.1052661589116008e-07 | Learning rate: 9.996401294534328e-10\n",
      "Error: 1.0800532611749623e-07 | Learning rate: 9.996301367494397e-10\n",
      "Error: 1.0554157535605059e-07 | Learning rate: 9.996201442452248e-10\n",
      "Error: 1.0313404992831704e-07 | Learning rate: 9.996101519407823e-10\n",
      "Error: 1.0078146613141359e-07 | Learning rate: 9.996001598361056e-10\n",
      "Finished after 4033735 iterations\n",
      "Testing with learn_rate: 1e-10 and decay_speed: 1e-05\n",
      "Error: 2.747382288591415e-06 | Learning rate: 9.99990000099999e-11\n",
      "Error: 1.0374175343462502e-06 | Learning rate: 4.999975000124999e-11\n",
      "Error: 5.884676081894426e-07 | Learning rate: 3.333322222259259e-11\n",
      "Error: 3.9414812758123374e-07 | Learning rate: 2.4999937500156253e-11\n",
      "Error: 2.8910693512113595e-07 | Learning rate: 1.999996000008e-11\n",
      "Error: 2.2458154095233965e-07 | Learning rate: 1.6666638888935184e-11\n",
      "Error: 1.8149190559762078e-07 | Learning rate: 1.4285693877580175e-11\n",
      "Error: 1.5096914150057018e-07 | Learning rate: 1.2499984375019533e-11\n",
      "Error: 1.2837784321811506e-07 | Learning rate: 1.1111098765445815e-11\n",
      "Error: 1.1107912178339563e-07 | Learning rate: 9.999990000009999e-12\n",
      "Finished after 979618 iterations\n",
      "Testing with learn_rate: 1e-10 and decay_speed: 1e-06\n",
      "Error: 2.747407015007286e-06 | Learning rate: 9.999990000010001e-11\n",
      "Error: 1.7002334985542586e-06 | Learning rate: 9.090900826453794e-11\n",
      "Error: 1.109453021635953e-06 | Learning rate: 8.333326388894677e-11\n",
      "Error: 7.590957125751078e-07 | Learning rate: 7.692301775152481e-11\n",
      "Error: 5.422024584510563e-07 | Learning rate: 7.14285204081997e-11\n",
      "Error: 4.0274981900554934e-07 | Learning rate: 6.666662222225185e-11\n",
      "Error: 3.0996602830549303e-07 | Learning rate: 6.249996093752442e-11\n",
      "Error: 2.4625036020988863e-07 | Learning rate: 5.882349480970894e-11\n",
      "Error: 2.0118024860080182e-07 | Learning rate: 5.5555524691375173e-11\n",
      "Error: 1.6839616102191816e-07 | Learning rate: 5.2631551246551974e-11\n",
      "Error: 1.439142165488648e-07 | Learning rate: 4.99999750000125e-11\n",
      "Error: 1.251787001403247e-07 | Learning rate: 4.761902494332146e-11\n",
      "Error: 1.1051338777259755e-07 | Learning rate: 4.545452479339782e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished after 1288686 iterations\n",
      "Testing with learn_rate: 1e-10 and decay_speed: 1e-07\n",
      "Error: 2.7474094876733518e-06 | Learning rate: 9.999999000000099e-11\n",
      "Error: 1.8211505593506928e-06 | Learning rate: 9.900989118713948e-11\n",
      "Error: 1.229376985802034e-06 | Learning rate: 9.803920607458764e-11\n",
      "Error: 8.500723615463424e-07 | Learning rate: 9.708736921481852e-11\n",
      "Error: 6.061404682063771e-07 | Learning rate: 9.615383690828491e-11\n",
      "Error: 4.4853608169306035e-07 | Learning rate: 9.523808616780131e-11\n",
      "Error: 3.4586842653545354e-07 | Learning rate: 9.433961374154588e-11\n",
      "Error: 2.780108614957982e-07 | Learning rate: 9.345793519084719e-11\n",
      "Error: 2.3213696366090305e-07 | Learning rate: 9.25925840192052e-11\n",
      "Error: 2.0017681539726152e-07 | Learning rate: 9.17431108492559e-11\n",
      "Error: 1.771186777883467e-07 | Learning rate: 9.090908264462886e-11\n",
      "Error: 1.59867082708276e-07 | Learning rate: 9.00900819738665e-11\n",
      "Error: 1.4649865763109753e-07 | Learning rate: 8.928570631377623e-11\n",
      "Error: 1.3579847500527986e-07 | Learning rate: 8.84955673897728e-11\n",
      "Error: 1.269813797960152e-07 | Learning rate: 8.771929055093943e-11\n",
      "Error: 1.1952731445509326e-07 | Learning rate: 8.695651417769443e-11\n",
      "Error: 1.1308375108710902e-07 | Learning rate: 8.620688912009577e-11\n",
      "Error: 1.0740684185233582e-07 | Learning rate: 8.547007816495059e-11\n",
      "Error: 1.0232496536374054e-07 | Learning rate: 8.474575553002072e-11\n",
      "Finished after 1849293 iterations\n",
      "Testing with learn_rate: 1e-10 and decay_speed: 1e-08\n",
      "Error: 2.7474097349402037e-06 | Learning rate: 9.999999900000002e-11\n",
      "Error: 1.8342693094088066e-06 | Learning rate: 9.990009890209692e-11\n",
      "Error: 1.2430652934731577e-06 | Learning rate: 9.980039820558486e-11\n",
      "Error: 8.607679981727678e-07 | Learning rate: 9.970089631404889e-11\n",
      "Error: 6.13884961334702e-07 | Learning rate: 9.960159263345028e-11\n",
      "Error: 4.5446363210645304e-07 | Learning rate: 9.950248657211457e-11\n",
      "Error: 3.5112396542838085e-07 | Learning rate: 9.940357754071992e-11\n",
      "Error: 2.833816014973461e-07 | Learning rate: 9.930486495228535e-11\n",
      "Error: 2.380321064652588e-07 | Learning rate: 9.920634822215926e-11\n",
      "Error: 2.067407347361882e-07 | Learning rate: 9.910802676800766e-11\n",
      "Error: 1.8435212079466603e-07 | Learning rate: 9.900990000980298e-11\n",
      "Error: 1.677078183306343e-07 | Learning rate: 9.891196736981238e-11\n",
      "Error: 1.548622132011787e-07 | Learning rate: 9.881422827258669e-11\n",
      "Error: 1.4459505231262645e-07 | Learning rate: 9.871668214494884e-11\n",
      "Error: 1.3612222420901107e-07 | Learning rate: 9.861932841598297e-11\n",
      "Error: 1.2892742935906533e-07 | Learning rate: 9.852216651702298e-11\n",
      "Error: 1.2266354163632042e-07 | Learning rate: 9.842519588164178e-11\n",
      "Error: 1.170933299115169e-07 | Learning rate: 9.832841594563995e-11\n",
      "Error: 1.1205261346350236e-07 | Learning rate: 9.823182614703512e-11\n",
      "Error: 1.0742659278020774e-07 | Learning rate: 9.813542592605077e-11\n",
      "Error: 1.031342293402845e-07 | Learning rate: 9.803921472510574e-11\n",
      "Finished after 2077494 iterations\n",
      "Testing with learn_rate: 1e-10 and decay_speed: 1e-09\n",
      "Error: 2.7474097596668916e-06 | Learning rate: 9.99999999e-11\n",
      "Error: 1.8355923716334729e-06 | Learning rate: 9.999000089992e-11\n",
      "Error: 1.244453756299116e-06 | Learning rate: 9.998000389924015e-11\n",
      "Error: 8.618570406402628e-07 | Learning rate: 9.997000889736078e-11\n",
      "Error: 6.146773218166046e-07 | Learning rate: 9.996001589368251e-11\n",
      "Error: 4.550768865916852e-07 | Learning rate: 9.995002488760617e-11\n",
      "Error: 3.5167795322657075e-07 | Learning rate: 9.994003587853284e-11\n",
      "Error: 2.8395866674028127e-07 | Learning rate: 9.993004886586386e-11\n",
      "Error: 2.3867453363989743e-07 | Learning rate: 9.992006384900074e-11\n",
      "Error: 2.0746292227452157e-07 | Learning rate: 9.991008082734531e-11\n",
      "Error: 1.8515359497882704e-07 | Learning rate: 9.99000998002996e-11\n",
      "Error: 1.6858168547013033e-07 | Learning rate: 9.98901207672659e-11\n",
      "Error: 1.5579926216161225e-07 | Learning rate: 9.988014372764669e-11\n",
      "Error: 1.4558538677358237e-07 | Learning rate: 9.987016868084474e-11\n",
      "Error: 1.3715588362745108e-07 | Learning rate: 9.986019562626305e-11\n",
      "Error: 1.299947013380472e-07 | Learning rate: 9.985022456330482e-11\n",
      "Error: 1.2375519479149165e-07 | Learning rate: 9.984025549137356e-11\n",
      "Error: 1.1820080276462373e-07 | Learning rate: 9.983028840987295e-11\n",
      "Error: 1.1316814884696241e-07 | Learning rate: 9.982032331820689e-11\n",
      "Error: 1.085433111637751e-07 | Learning rate: 9.981036021577966e-11\n",
      "Error: 1.0424614690496265e-07 | Learning rate: 9.980039910199561e-11\n",
      "Error: 1.0021974050066567e-07 | Learning rate: 9.979043997625941e-11\n",
      "Finished after 2105636 iterations\n",
      "Testing with learn_rate: 1e-10 and decay_speed: 1e-10\n",
      "Error: 2.74740976213956e-06 | Learning rate: 9.999999999e-11\n",
      "Error: 1.8357247907271538e-06 | Learning rate: 9.99990000000001e-11\n",
      "Error: 1.244592802028259e-06 | Learning rate: 9.999800002999962e-11\n",
      "Error: 8.619661440752483e-07 | Learning rate: 9.999700007999791e-11\n",
      "Error: 6.147567431590096e-07 | Learning rate: 9.99960001499944e-11\n",
      "Error: 4.5513842793817554e-07 | Learning rate: 9.999500023998851e-11\n",
      "Error: 3.5173365588255037e-07 | Learning rate: 9.99940003499796e-11\n",
      "Error: 2.8401680430994214e-07 | Learning rate: 9.99930004799671e-11\n",
      "Error: 2.3873934999052483e-07 | Learning rate: 9.99920006299504e-11\n",
      "Error: 2.0753585821594798e-07 | Learning rate: 9.999100079992892e-11\n",
      "Error: 1.8523459908640197e-07 | Learning rate: 9.999000098990201e-11\n",
      "Error: 1.6867006277950272e-07 | Learning rate: 9.998900119986911e-11\n",
      "Error: 1.5589408463937757e-07 | Learning rate: 9.998800142982963e-11\n",
      "Error: 1.456856557567412e-07 | Learning rate: 9.998700167978294e-11\n",
      "Error: 1.3726059165755483e-07 | Learning rate: 9.998600194972844e-11\n",
      "Error: 1.3010286417055352e-07 | Learning rate: 9.998500223966555e-11\n",
      "Error: 1.2386587528349833e-07 | Learning rate: 9.998400254959367e-11\n",
      "Error: 1.1831313087451352e-07 | Learning rate: 9.998300287951218e-11\n",
      "Error: 1.132813354431393e-07 | Learning rate: 9.99820032294205e-11\n",
      "Error: 1.0865665602481874e-07 | Learning rate: 9.998100359931804e-11\n",
      "Error: 1.043590402808969e-07 | Learning rate: 9.998000398920416e-11\n",
      "Error: 1.0033166123393508e-07 | Learning rate: 9.99790043990783e-11\n",
      "Finished after 2108511 iterations\n"
     ]
    }
   ],
   "source": [
    "learn_rates = [10**(-5), 10**(-6), 10**(-7), 10**(-8), 10**(-9), 10**(-10)]\n",
    "decay_speeds = [10**(-5), 10**(-6), 10**(-7), 10**(-8), 10**(-9), 10**(-10)]\n",
    "min_error = 10**(-7)\n",
    "\n",
    "train_grad_errors = []\n",
    "valid_grad_errors = []\n",
    "grad_runtimes = []\n",
    "for learn_rate in learn_rates:\n",
    "    train_err = []\n",
    "    valid_err = []\n",
    "    run = []\n",
    "    for decay_speed in decay_speeds:\n",
    "        print(f'Testing with learn_rate: {learn_rate} and decay_speed: {decay_speed}')\n",
    "        hyperparams = {'decay_speed': decay_speed, 'learn_rate': learn_rate, 'min_err': min_error, 'max_iter': 10000000}\n",
    "        perf = test_closed_vs_gradient(X_train, y_train, X_valid, y_valid, hyperparams)\n",
    "        train_err.append(perf['train']['grad'])\n",
    "        valid_err.append(perf['validation']['grad'])\n",
    "        run.append(perf['runtime']['grad'])\n",
    "    train_grad_errors.append(train_err)\n",
    "    valid_grad_errors.append(valid_err)\n",
    "    grad_runtimes.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for gradient descent on training set:\n",
      "\n",
      "  Learn rate/decay speed    1e-05    1e-06    1e-07    1e-08    1e-09    1e-10\n",
      "------------------------  -------  -------  -------  -------  -------  -------\n",
      "                   1e-05  1.08468  1.08468  1.08468  1.08468  1.08468  1.08468\n",
      "                   1e-06  1.08468  1.08468  1.08468  1.08468  1.08468  1.08468\n",
      "                   1e-07  1.08469  1.08468  1.08468  1.08468  1.08468  1.08468\n",
      "                   1e-08  1.08883  1.08484  1.08471  1.08471  1.0847   1.0847\n",
      "                   1e-09  1.10789  1.09433  1.08849  1.08702  1.08687  1.08685\n",
      "                   1e-10  1.31064  1.13619  1.1141   1.10975  1.10927  1.10922\n"
     ]
    }
   ],
   "source": [
    "data = deepcopy(train_grad_errors)\n",
    "for err, learn_rate in zip(data, learn_rates):\n",
    "    err.insert(0, learn_rate)\n",
    "table = tabulate(data, headers=['Learn rate/decay speed'] + decay_speeds)\n",
    "print('MSE for gradient descent on training set:\\n')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for gradient descent on validation set:\n",
      "\n",
      "  Learn rate/decay speed    1e-05    1e-06    1e-07    1e-08    1e-09    1e-10\n",
      "------------------------  -------  -------  -------  -------  -------  -------\n",
      "                   1e-05  1.02033  1.02033  1.02033  1.02033  1.02033  1.02033\n",
      "                   1e-06  1.02033  1.02033  1.02033  1.02033  1.02033  1.02033\n",
      "                   1e-07  1.02043  1.02035  1.02035  1.02034  1.02034  1.02034\n",
      "                   1e-08  1.02567  1.02091  1.02055  1.02052  1.02052  1.02052\n",
      "                   1e-09  1.04722  1.03106  1.02533  1.02381  1.02364  1.02362\n",
      "                   1e-10  1.25706  1.07942  1.0544   1.04938  1.04882  1.04876\n"
     ]
    }
   ],
   "source": [
    "data = deepcopy(valid_grad_errors)\n",
    "for err, learn_rate in zip(data, learn_rates):\n",
    "    err.insert(0, learn_rate)\n",
    "table = tabulate(data, headers=['Learn rate/decay speed'] + decay_speeds)\n",
    "print('MSE for gradient descent on validation set:\\n')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime(s) for gradient descent:\n",
      "\n",
      "  Learn rate/decay speed      1e-05       1e-06       1e-07       1e-08       1e-09       1e-10\n",
      "------------------------  ---------  ----------  ----------  ----------  ----------  ----------\n",
      "                   1e-05   0.116059   0.0703435   0.0984132   0.0703449   0.0693622   0.0745676\n",
      "                   1e-06   0.479676   0.383047    0.451919    0.475055    0.384151    0.396765\n",
      "                   1e-07   4.29145    2.61122     2.65114     2.64536     2.28122     2.40449\n",
      "                   1e-08  12.8545    16.5609     13.7615     13.3415     13.4917     15.1541\n",
      "                   1e-09   9.24393   14.7336     33.6424     40.2988     40.3629     40.6455\n",
      "                   1e-10   9.75323   13.606      18.1443     20.3933     21.5642     20.6675\n"
     ]
    }
   ],
   "source": [
    "data = deepcopy(grad_runtimes)\n",
    "for runtime, learn_rate in zip(data, learn_rates):\n",
    "    runtime.insert(0, learn_rate)\n",
    "table = tabulate(data, headers=['Learn rate/decay speed'] + decay_speeds)\n",
    "print('Runtime(s) for gradient descent:\\n')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Compare models using no text, top 60 words and top 160 words features using closed-form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.1 - No text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAFNCAYAAABVKNEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set MSE\n",
      "Top words 0: 1.0846830709157251\n",
      "Top words 60: 1.060429141685383\n",
      "Top words 160: 1.0477763217987115\n",
      "Validation set MSE\n",
      "Top words 0: 1.0846830709157251\n",
      "Top words 60: 1.060429141685383\n",
      "Top words 160: 1.0477763217987115\n"
     ]
    }
   ],
   "source": [
    "mse_train = []\n",
    "mse_valid = []\n",
    "\n",
    "step = 2\n",
    "num_features = list(range(0, 161, step))\n",
    "\n",
    "for i in num_features:\n",
    "    X_train_i, y_train_i = ppd.compute_features(train, extra_features=False, num_word_features=i)\n",
    "    X_valid_i, y_valid_i = ppd.compute_features(validation, extra_features=False, num_word_features=i)\n",
    "    w_i = linear_closed_form(X_train_i, y_train_i)\n",
    "\n",
    "    # Compute MSE on train set\n",
    "    y_train_i = np.matmul(X_train_i, w_i)\n",
    "    mse_train_i = np.sum((y_train_i - y_train)**2)/len(y_train)\n",
    "\n",
    "    # Compute MSE on validation set\n",
    "    y_valid_i = np.matmul(X_valid_i, w_i)\n",
    "    mse_valid_i = np.sum((y_valid_i - y_valid)**2)/len(y_valid)\n",
    "\n",
    "    mse_train.append(mse_train_i)\n",
    "    mse_valid.append(mse_valid_i)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(num_features, mse_train, 'g-', label='Train Set')\n",
    "plt.plot(num_features, mse_valid, 'b-', label='Validation Set')\n",
    "plt.legend(loc='center right')\n",
    "plt.title('Closed-form LR Models - Top Words Features')\n",
    "plt.xlabel('Number of top words'), plt.ylabel('MSE')\n",
    "plt.show()\n",
    "\n",
    "print('Train set MSE')\n",
    "print(f'Top words 0: {mse_train[0]}')\n",
    "print(f'Top words 60: {mse_train[60//step]}')\n",
    "print(f'Top words 160: {mse_train[160//step]}')\n",
    "\n",
    "print('Validation set MSE')\n",
    "print(f'Top words 0: {mse_train[0]}')\n",
    "print(f'Top words 60: {mse_train[60//step]}')\n",
    "print(f'Top words 160: {mse_train[160//step]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Demonstrate performance of new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute most common words from\n",
    "ppd.compute_most_common_words(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64)\n",
      "(1000, 64)\n",
      "Training features runtime: 0.2501492500305176\n",
      "Validation features runtime: 0.022776365280151367\n"
     ]
    }
   ],
   "source": [
    "# Baseline - no extra features\n",
    "# Compute features on training set\n",
    "start = time.time()\n",
    "X_train, y_train = ppd.compute_features(train, extra_features=False, num_word_features=60)\n",
    "feat_train_runtime = time.time() - start\n",
    "print(X_train.shape)\n",
    "\n",
    "# Compute features on validation set\n",
    "start = time.time()\n",
    "X_valid, y_valid = ppd.compute_features(validation, extra_features=False, num_word_features=60)\n",
    "feat_valid_runtime = time.time() - start\n",
    "print(X_valid.shape)\n",
    "\n",
    "print(f'Training features runtime: {feat_train_runtime}')\n",
    "print(f'Validation features runtime: {feat_valid_runtime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983939729721766\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "w_init = np.zeros(X_train.shape[1])\n",
    "# w_grad = linear_gradient_descent(X_train, y_train, w_init, decay_speed=10**(-10), learn_rate=10**(-8), min_err=10**(-7), max_iter=10000000, verbose=True)\n",
    "w_grad = linear_closed_form(X_train, y_train)\n",
    "\n",
    "# Compute MSE on validation set\n",
    "y_grad_valid = np.matmul(X_valid, w_grad)\n",
    "mse_grad_valid = np.sum((y_grad_valid - y_valid)**2)/len(y_valid)\n",
    "print(mse_grad_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 70)\n",
      "(1000, 70)\n",
      "Training features runtime: 0.8176195621490479\n",
      "Validation features runtime: 0.0820925235748291\n"
     ]
    }
   ],
   "source": [
    "# Extra features\n",
    "# Compute features on training set\n",
    "start = time.time()\n",
    "X_train_extra, y_train_extra = ppd.compute_features(train, extra_features=True, num_word_features=60)\n",
    "feat_train_runtime = time.time() - start\n",
    "print(X_train_extra.shape)\n",
    "\n",
    "# Compute features on validation set\n",
    "start = time.time()\n",
    "X_valid_extra, y_valid_extra = ppd.compute_features(validation, extra_features=True, num_word_features=60)\n",
    "feat_valid_runtime = time.time() - start\n",
    "print(X_valid_extra.shape)\n",
    "\n",
    "print(f'Training features runtime: {feat_train_runtime}')\n",
    "print(f'Validation features runtime: {feat_valid_runtime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9817493486951205\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "w_init_extra = np.zeros(X_train_extra.shape[1])\n",
    "# w_grad_extra = linear_gradient_descent(X_train_extra, y_train_extra, w_init_extra, decay_speed=10**(-10), learn_rate=10**(-8), min_err=10**(-7), max_iter=10000000, verbose=True)\n",
    "w_grad_extra = linear_closed_form(X_train_extra, y_train_extra)\n",
    "\n",
    "# Compute MSE on validation set\n",
    "y_grad_valid_extra = np.matmul(X_valid_extra, w_grad_extra)\n",
    "mse_grad_valid_extra = np.sum((y_grad_valid_extra - y_valid_extra)**2)/len(y_valid_extra)\n",
    "print(mse_grad_valid_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021903810266454826\n"
     ]
    }
   ],
   "source": [
    "print(mse_grad_valid - mse_grad_valid_extra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
